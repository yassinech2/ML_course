{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import  *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "import seaborn as sns\n",
    "plt.rcParams['text.usetex'] = False\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"data/dataset_to_release/\", sub_sample=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (y_train + 1) / 2\n",
    "column_names = np.genfromtxt(\"data/dataset/x_train.csv\", delimiter=\",\", dtype=str, max_rows=1)\n",
    "column_names.shape\n",
    "column_names = column_names[1:]\n",
    "nan_counts = np.isnan(x_train).sum(axis=0)\n",
    "columns_to_remove = np.where(nan_counts > x_train.shape[0]/3)[0]\n",
    "\n",
    "\n",
    "x_clean = np.delete(x_train, columns_to_remove, axis=1)\n",
    "x_clean_test = np.delete(x_test, columns_to_remove, axis=1)\n",
    "column_names_clean = np.delete(column_names, columns_to_remove, axis=0)\n",
    "\n",
    "\n",
    "#replace nan values with the median of the column\n",
    "medians = np.nanmedian(x_clean, axis=0)\n",
    "x_clean[np.isnan(x_clean)] = np.take(medians, np.isnan(x_clean).nonzero()[1])\n",
    "\n",
    "medians_test = np.nanmedian(x_clean_test, axis=0)\n",
    "x_clean_test[np.isnan(x_clean_test)] = np.take(medians_test, np.isnan(x_clean_test).nonzero()[1])\n",
    "assert np.isnan(x_clean).sum() == 0 and np.isnan(x_clean_test).sum() == 0, \"There are still nan values in the data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cat_features=['BPHIGH4'\n",
    ",'_RFHLTH','_RFHYPE5','_DRDXAR1','DIABETE3'\n",
    ",'DIFFWALK','TOLDHI2','_RFCHOL','HAVARTH3','QLACTLM2'\n",
    ",'CVDSTRK3','PNEUVAC3'\n",
    ",'CHCCOPD1','SMOKE100','SEX','DIFFALON','_LMTACT1','CHCOCNCR','_BMI5CAT'\n",
    ",'DIFFDRES']\n",
    "relevant_non_cat_features =['_AGE80','STRENGTH','ALCDAY5','WTKG3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand matrix by one hot encoding\n",
    "x_train_one_hot = one_hot_encoder(x_clean, column_names_clean, relevant_cat_features)\n",
    "\n",
    "x_test_one_hot = one_hot_encoder(x_clean_test, column_names_clean, relevant_cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_one_hot = concat_features(x_clean, x_train_one_hot, relevant_non_cat_features)\n",
    "x_test_one_hot = concat_features(x_clean_test, x_test_one_hot, relevant_non_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239373, 70)\n",
      "undersampling over\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.8\n",
    "seed = 1\n",
    "x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(x_train_one_hot, y_train, test_size=1-ratio, random_state=seed)\n",
    "\n",
    "# Appy SMOTE on the training data for oversampling\n",
    "x_train_smote, y_train_smote = SMOTE(x_train_split, y_train_split, k=5, ratio=0.5)\n",
    "# Undersampling the training data\n",
    "x_train_under, y_train_under = undersample_majority(x_train_smote, y_train_smote, ratio=0.8)\n",
    "\n",
    "\n",
    "x_stan_train, mean_x, std_x = standardize(x_train_under)\n",
    "x_stan_val = (x_val_split-mean_x) / std_x\n",
    "x_stan_test = (x_test_one_hot - mean_x) / std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss=4.16434087847291\n",
      "Current iteration=0, loss=8.293999789863093\n",
      "Current iteration=100, loss=3.316741888822076\n",
      "Current iteration=200, loss=2.230712704446871\n",
      "Current iteration=300, loss=1.606999060060923\n",
      "Current iteration=400, loss=1.2137099833866278\n",
      "Current iteration=500, loss=0.9623781121465614\n",
      "Current iteration=600, loss=0.8010096636372728\n",
      "Current iteration=700, loss=0.6970369510892707\n",
      "Current iteration=800, loss=0.6297492135826475\n",
      "Current iteration=900, loss=0.5859579491260033\n",
      "Current iteration=1000, loss=0.5573047328486493\n",
      "Current iteration=1100, loss=0.5384677890623831\n",
      "Current iteration=1200, loss=0.5260313999753541\n",
      "Current iteration=1300, loss=0.517790877089902\n",
      "Current iteration=1400, loss=0.5123150400847093\n",
      "Current iteration=1500, loss=0.5086687069538858\n",
      "Current iteration=1600, loss=0.5062370023901002\n",
      "Current iteration=1700, loss=0.5046136205435933\n",
      "Current iteration=1800, loss=0.503529072453409\n",
      "Current iteration=1900, loss=0.5028041364659172\n",
      "Current iteration=2000, loss=0.502319398302284\n",
      "Current iteration=2100, loss=0.5019951886204364\n",
      "Current iteration=2200, loss=0.5017783060841883\n",
      "Current iteration=2300, loss=0.5016332014352689\n",
      "Current iteration=2400, loss=0.5015361099493171\n",
      "Current iteration=2500, loss=0.5014711398492394\n",
      "Current iteration=2600, loss=0.5014276616939025\n",
      "Current iteration=2700, loss=0.5013985646647512\n",
      "Current iteration=2800, loss=0.5013790912359086\n",
      "Current iteration=2900, loss=0.5013660580749073\n",
      "Current iteration=3000, loss=0.5013573350183911\n",
      "Current iteration=3100, loss=0.5013514965658205\n",
      "Current iteration=3200, loss=0.5013475887338472\n",
      "Current iteration=3300, loss=0.5013449730681946\n",
      "Current iteration=3400, loss=0.5013432222697574\n",
      "Current iteration=3500, loss=0.501342050352019\n",
      "Current iteration=3600, loss=0.5013412659029665\n",
      "Current iteration=3700, loss=0.5013407408070423\n",
      "Current iteration=3800, loss=0.5013403893125321\n",
      "Current iteration=3900, loss=0.5013401540221437\n",
      "Current iteration=4000, loss=0.5013399965167814\n",
      "Current iteration=4100, loss=0.5013398910800775\n",
      "Current iteration=4200, loss=0.5013398204981625\n",
      "Current iteration=4300, loss=0.5013397732483564\n",
      "Current iteration=4400, loss=0.5013397416174641\n",
      "Current iteration=4500, loss=0.5013397204422627\n",
      "Current iteration=4600, loss=0.5013397062664425\n",
      "Current iteration=4700, loss=0.5013396967762881\n",
      "Current iteration=4800, loss=0.5013396904229394\n",
      "Current iteration=4900, loss=0.5013396861695388\n",
      "Current iteration=5000, loss=0.5013396833219719\n",
      "Current iteration=5100, loss=0.5013396814155646\n",
      "Current iteration=5200, loss=0.5013396801392396\n",
      "Current iteration=5300, loss=0.5013396792847423\n",
      "Current iteration=5400, loss=0.5013396787126531\n",
      "Current iteration=5500, loss=0.5013396783296339\n",
      "Current iteration=5600, loss=0.5013396780731968\n",
      "Current iteration=5700, loss=0.5013396779015068\n",
      "Current iteration=5800, loss=0.501339677786556\n",
      "Current iteration=5900, loss=0.501339677709593\n",
      "Current iteration=6000, loss=0.5013396776580635\n",
      "Current iteration=6100, loss=0.5013396776235622\n",
      "Current iteration=6200, loss=0.5013396776004623\n",
      "Current iteration=6300, loss=0.5013396775849955\n",
      "Current iteration=6400, loss=0.5013396775746398\n",
      "Current iteration=6500, loss=0.501339677567706\n",
      "Current iteration=6600, loss=0.5013396775630634\n",
      "Current iteration=6700, loss=0.5013396775599548\n",
      "Current iteration=6800, loss=0.5013396775578735\n",
      "Current iteration=6900, loss=0.5013396775564798\n",
      "Current iteration=7000, loss=0.5013396775555465\n",
      "Current iteration=7100, loss=0.5013396775549218\n",
      "Current iteration=7200, loss=0.5013396775545034\n",
      "Current iteration=7300, loss=0.5013396775542232\n",
      "Current iteration=7400, loss=0.5013396775540356\n",
      "Current iteration=7500, loss=0.5013396775539101\n",
      "Current iteration=7600, loss=0.5013396775538259\n",
      "Current iteration=7700, loss=0.5013396775537696\n",
      "Current iteration=7800, loss=0.5013396775537319\n",
      "Current iteration=7900, loss=0.5013396775537068\n",
      "Current iteration=8000, loss=0.5013396775536898\n",
      "Current iteration=8100, loss=0.5013396775536785\n",
      "Current iteration=8200, loss=0.5013396775536708\n",
      "Current iteration=8300, loss=0.5013396775536658\n",
      "Current iteration=8400, loss=0.5013396775536624\n",
      "Current iteration=8500, loss=0.50133967755366\n",
      "Current iteration=8600, loss=0.5013396775536586\n",
      "Current iteration=8700, loss=0.5013396775536576\n",
      "Current iteration=8800, loss=0.5013396775536569\n",
      "Current iteration=8900, loss=0.5013396775536565\n",
      "Current iteration=9000, loss=0.5013396775536562\n",
      "Current iteration=9100, loss=0.5013396775536558\n",
      "Current iteration=9200, loss=0.5013396775536558\n",
      "Current iteration=9300, loss=0.5013396775536557\n",
      "Current iteration=9400, loss=0.5013396775536556\n",
      "Current iteration=9500, loss=0.5013396775536556\n",
      "Current iteration=9600, loss=0.5013396775536555\n",
      "Current iteration=9700, loss=0.5013396775536555\n",
      "Current iteration=9800, loss=0.5013396775536555\n",
      "Current iteration=9900, loss=0.5013396775536556\n"
     ]
    }
   ],
   "source": [
    "y, tx_train = build_model_data(y_train_under, x_stan_train_extended)\n",
    "initial_w = np.random.rand(tx_train.shape[1])\n",
    "w,loss = reg_logistic_regression(y, tx_train, 0.1, initial_w , 10000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Validation Set: 0.7188047602358785\n",
      "F1 score for Validation Set: 0.34759244856112564\n",
      "16606.0\n"
     ]
    }
   ],
   "source": [
    "val_tx = np.c_[np.ones(x_stan_val_extended.shape[0]), x_stan_val_extended]\n",
    "y_pred_val = predict(val_tx, w, threshold = 0.5)\n",
    "y_pred_val = (y_pred_val + 1) / 2\n",
    "print(\"Accuracy for Validation Set:\", accuracy(y_val_split, y_pred_val))\n",
    "print(\"F1 score for Validation Set:\", compute_f1_score(y_val_split, y_pred_val))\n",
    "print((y_pred_val - y_val_split).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.70\n",
      "Accuracy for Validation Set at Best Threshold: 0.8556082100355037\n",
      "F1 score for Validation Set at Best Threshold: 0.4099626400996264\n"
     ]
    }
   ],
   "source": [
    "best_threshold = select_best_threshold(y_val_split,val_tx,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tx = np.c_[np.ones(x_stan_test_extended.shape[0]), x_stan_test_extended]\n",
    "y_pred = predict(test_tx,w,threshold = best_threshold)\n",
    "create_csv_submission(test_ids, y_pred, 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
